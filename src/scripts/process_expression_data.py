import pandas as pd
import dask
import dask.dataframe as dd
import argparse

def expression_file_loader(included_ids, cutoff):
    #Function to load the raw expression data and discard anything we don't need.
    #Might give an empty dataframe if not refreshing and no new data.
    expression_data = dd.read_parquet("tmp/expression_data/", filters=[('id', 'in', included_ids)])
    if not included_ids:
        print("No new expression data to load.")
        return dd.from_pandas(pd.DataFrame(), npartitions=1)
    expression_data = expression_data[(expression_data['expression_extent']>cutoff)].set_index('id')
    return expression_data


if __name__ == "__main__":
    # run the expression processing only if this is run rather than imported
    
    # can specify whether to regenerate tsvs for all existing datasets.
    # New datasets will always be generated.
    parser = argparse.ArgumentParser()
    parser.add_argument("-r", "--refresh", help="refresh all existing expression data",
                        action="store_true")
    args = parser.parse_args()

    expression_cutoff = 0.2

    # excluded clusters and existing entities
    all_inclusions = []
    with open('tmp/all_inclusions.txt', 'r') as file: # generated by process_metadata
        for line in file:
            all_inclusions.append(line.rstrip())

    existing_entities = []
    if not args.refresh:
        with open('tmp/internal_terms.txt', 'r') as file: # all FBlcs in owl files
            for line in file:
                existing_entities.append("FlyBase:" + line.rstrip())

    included_entities_to_update = [e for e in all_inclusions if not (e in existing_entities)]

    # EXPRESSION DATA

    # make dict of cluster:dataset
    cluster_metadata = pd.read_csv("tmp/raw_cluster_data.tsv", sep='\t').set_index('id')
    dataset_cluster_dict = {c: cluster_metadata['associated_dataset'][c] for c in cluster_metadata.index.values}

    expression_data = expression_file_loader(included_entities_to_update, expression_cutoff)

    if expression_data.size.compute() > 0:
        def expression_outfile_namer(n):
            dataset = dataset_cluster_dict[expression_data.divisions[n]].replace("FlyBase:", "")
            cluster = expression_data.divisions[n].replace("FlyBase:", "")
            filename = f"VFB_scRNAseq_exp_{dataset}-cluster_{cluster}"
            return filename
        expression_data.to_csv("expression_data/*.tsv", name_function=expression_outfile_namer, sep='\t')
