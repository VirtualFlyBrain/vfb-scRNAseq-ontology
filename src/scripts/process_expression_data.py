import pandas as pd
import argparse

# can specify whether to regenerate tsvs for all existing datasets. New datasets will always be generated.
parser = argparse.ArgumentParser()
parser.add_argument("-r", "--refresh", help="refresh all existing metadata",
                    action="store_true")
args = parser.parse_args()

expression_cutoff = 0.2

# excluded clusters and existing entities
all_inclusions = []
with open('tmp/all_inclusions.txt', 'r') as file: # generated by process_metadata
    for line in file:
        all_inclusions.append(line.rstrip())

existing_entities = []
if not args.refresh:
    with open('tmp/internal_terms.txt', 'r') as file: # all FBlcs in owl files
        for line in file:
            existing_entities.append("FlyBase:" + line.rstrip())

included_entities_to_update = all_inclusions - existing_entities

# EXPRESSION DATA

# make dict of cluster:dataset
cluster_metadata = pd.read_csv("tmp/raw_cluster_data.tsv", sep='\t').set_index('id')
dataset_cluster_dict = {c: cluster_metadata['associated_dataset'][c] for c in cluster_metadata.index.values}

# get headers from expression_data file
expression_data = pd.read_csv("tmp/raw_expression_data.tsv", sep='\t', nrows=0)

# read expression_data in chunksize
expression_reader = pd.read_csv("tmp/raw_expression_data.tsv", sep='\t', dtype={'id': 'category', 'gene': 'category'}, chunksize=1000)

# filter each chunk and concatenate
for chunk in expression_reader:
    filtered = chunk[(chunk['expression_extent']>expression_cutoff) & (chunk['id'].isin(included_entities_to_update))]
    expression_data = pd.concat([expression_data, filtered])

# make a a tsv for each new cluster
clusters = expression_data['id'].unique()
print(str(len(clusters)) + ' clusters')
for c in clusters:
    cluster_data = expression_data[expression_data['id']==c]
    cluster_data = cluster_data.assign(hide_in_terminfo = 'true')
    cluster_id = c.replace("FlyBase:", "")
    cluster_data.to_csv("expression_data/dataset_%s-cluster_%s.tsv" % (dataset_cluster_dict[c].replace("FlyBase:", ""), cluster_id), sep='\t', index=False)
